{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qfSFD3B_nL1"
   },
   "source": [
    "## Installing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 14547,
     "status": "ok",
     "timestamp": 1731128694635,
     "user": {
      "displayName": "Stan Wang (王家宏)",
      "userId": "17655850901040918693"
     },
     "user_tz": -480
    },
    "id": "4b-spj2orPIm",
    "outputId": "964737ff-38f2-483a-88bc-d0077ea96efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Requirement already satisfied: f in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
      "Requirement already satisfied: Six in /usr/local/lib/python3.10/dist-packages (from f) (1.16.0)\n",
      "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rank_bm25) (1.26.4)\n",
      "Requirement already satisfied: ckip-transformers in /usr/local/lib/python3.10/dist-packages (0.3.4)\n",
      "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from ckip-transformers) (2.5.0+cu121)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from ckip-transformers) (4.66.6)\n",
      "Requirement already satisfied: transformers>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from ckip-transformers) (4.44.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip-transformers) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip-transformers) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip-transformers) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->ckip-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.5.0->ckip-transformers) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip-transformers) (0.24.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip-transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip-transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.5.0->ckip-transformers) (0.19.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->ckip-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.5.0->ckip-transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.5.0->ckip-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.5.0->ckip-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=3.5.0->ckip-transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber\n",
    "!pip install f\n",
    "!pip install rank_bm25\n",
    "!pip install -U ckip-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J27P6Jld_zH-"
   },
   "source": [
    "## Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12592,
     "status": "ok",
     "timestamp": 1731128707224,
     "user": {
      "displayName": "Stan Wang (王家宏)",
      "userId": "17655850901040918693"
     },
     "user_tz": -480
    },
    "id": "xE856zb7qgan",
    "outputId": "3ed21dc2-bf58-4c83-a2f7-8ce20c45a56a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import jieba\n",
    "import pdfplumber\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTSAbytJRAV2"
   },
   "source": [
    "## Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1731140150267,
     "user": {
      "displayName": "Stan Wang (王家宏)",
      "userId": "17655850901040918693"
     },
     "user_tz": -480
    },
    "id": "RW0PsSVoRB_N"
   },
   "outputs": [],
   "source": [
    "stop_word_path = \"./dataset/preliminary/stopwords.txt\"\n",
    "question_path = \"./dataset/preliminary/questions_example.json\" # 問題文件的路徑\n",
    "dict_path = \"./dataset/preliminary/dict.txt.big\"\n",
    "prompt_path = \"./dataset/preliminary/prompt.txt\"\n",
    "source_path = \"./reference\" # 參考資料的路徑\n",
    "output_path = \"./dataset/preliminary/pred_retrieve.json\" # 答案輸出的路徑\n",
    "truth_sample_path = \"./dataset/preliminary/ground_truths_example.json\"\n",
    "pred_sample_path = \"./dataset/preliminary/pred_retrieve.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opqvwZ3TAKil"
   },
   "source": [
    "## load/read function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入參考資料，返回一個字典，key為檔案名稱，value為PDF檔內容的文本\n",
    "def load_data(source_path):\n",
    "    masked_file_ls = os.listdir(source_path)  # 獲取資料夾中的檔案列表\n",
    "    corpus_dict = {int(file.replace('.pdf', '')): read_pdf(os.path.join(source_path, file)) for file in tqdm(masked_file_ls)}  # 讀取每個PDF文件的文本，並以檔案名作為鍵，文本內容作為值存入字典\n",
    "    return corpus_dict\n",
    "\n",
    "\n",
    "# 讀取單個PDF文件並返回其文本內容\n",
    "def read_pdf(pdf_loc, page_infos: list = None):\n",
    "    pdf = pdfplumber.open(pdf_loc)  # 打開指定的PDF文件\n",
    "\n",
    "    # TODO: 可自行用其他方法讀入資料，或是對pdf中多模態資料（表格,圖片等）進行處理\n",
    "\n",
    "    # 如果指定了頁面範圍，則只提取該範圍的頁面，否則提取所有頁面\n",
    "    pages = pdf.pages[page_infos[0]:page_infos[1]] if page_infos else pdf.pages\n",
    "    pdf_text = ''\n",
    "    for _, page in enumerate(pages):  # 迴圈遍歷每一頁\n",
    "        text = page.extract_text()  # 提取頁面的文本內容\n",
    "        if text:\n",
    "            pdf_text += text\n",
    "            pdf.close()  # 關閉PDF文件\n",
    "\n",
    "    return pdf_text  # 返回萃取出的文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyYMjFRRAEvt"
   },
   "source": [
    "## Cleaning text function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2241,
     "status": "ok",
     "timestamp": 1731138072438,
     "user": {
      "displayName": "Stan Wang (王家宏)",
      "userId": "17655850901040918693"
     },
     "user_tz": -480
    },
    "id": "e9ysDv2XqoAw",
    "outputId": "67b3b37e-ec2a-4186-b6dc-06f32a59a84d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /content/drive/MyDrive/Colab Notebooks/AICUP/dataset/preliminary/dict.txt.big ...\n",
      "DEBUG:jieba:Building prefix dict from /content/drive/MyDrive/Colab Notebooks/AICUP/dataset/preliminary/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u610a394bc606bc52a272eabd0137bb7f.cache\n",
      "DEBUG:jieba:Loading model from cache /tmp/jieba.u610a394bc606bc52a272eabd0137bb7f.cache\n",
      "Loading model cost 1.569 seconds.\n",
      "DEBUG:jieba:Loading model cost 1.569 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "DEBUG:jieba:Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load stopwords\n",
    "def load_stopwords(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        stopwords = set(f.read().splitlines())\n",
    "    return stopwords\n",
    "\n",
    "stopwords = load_stopwords(stop_word_path)\n",
    "\n",
    "jieba.set_dictionary(dict_path)\n",
    "\n",
    "def diction():\n",
    "    # 開啟並讀取檔案\n",
    "    with open(prompt_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # 移除行末的換行符號及多餘的空白\n",
    "            word = line.strip()\n",
    "            # 確保詞彙非空\n",
    "            if word:\n",
    "                jieba.add_word(word)\n",
    "\n",
    "diction()\n",
    "\n",
    "def clean_text(text, comment):\n",
    "    # Remove punctuation\n",
    "    if (comment):\n",
    "      punct_pattern = r'[\\s+\\.\\!\\/_,$%^*(+\\\"\\'’“”‘’]+|[+——！，。？、~@#￥%……&*（）]+'\n",
    "      text = \"\".join(c for c in text if c not in ('；','，','。','！','：','「','」','…','、','？','【','】','.',':','?',';','!','~','`','+','-','<','>','/','[',']','{','}',\"'\",'\"'))\n",
    "      text = re.sub(punct_pattern, '', text)\n",
    "\n",
    "      # Normalize whitespace\n",
    "      text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "      if not text:\n",
    "        return []\n",
    "\n",
    "      # Tokenization\n",
    "      tokens = list(jieba.cut_for_search(text))\n",
    "\n",
    "      # Remove stopwords\n",
    "      tokens = [word for word in tokens if word not in stopwords]\n",
    "    else:\n",
    "      tokens = list(jieba.cut_for_search(text))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtkPE61tAUbr"
   },
   "source": [
    "## Retrieve algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用基於 Dirichlet 平滑的語言模型進行檢索\n",
    "def LMIR_retrieve(qs, source, corpus_dict):\n",
    "    # 根據來源取得過濾後的語料庫\n",
    "    filtered_corpus = [corpus_dict[int(file)] for file in source]\n",
    "    doc_ids = [int(file) for file in source]\n",
    "\n",
    "    # 對文件和查詢進行分詞\n",
    "    tokenized_corpus = [clean_text(doc,True) for doc in filtered_corpus]\n",
    "    tokenized_query = clean_text(qs,True)\n",
    "\n",
    "    # 計算語料庫中的詞頻\n",
    "    corpus_term_freq = Counter()\n",
    "    for doc_tokens in tokenized_corpus:\n",
    "        corpus_term_freq.update(doc_tokens)\n",
    "    corpus_length = sum(corpus_term_freq.values())\n",
    "\n",
    "    # 預先計算每個文件的長度和詞頻\n",
    "    doc_term_freqs = []\n",
    "    doc_lengths = []\n",
    "    for doc_tokens in tokenized_corpus:\n",
    "        term_freq = Counter(doc_tokens)\n",
    "        doc_term_freqs.append(term_freq)\n",
    "        doc_lengths.append(len(doc_tokens))\n",
    "\n",
    "    # 設定 Dirichlet 平滑參數 mu\n",
    "    mu = 3000\n",
    "\n",
    "    # 計算每個文件的查詢似然\n",
    "    scores = []\n",
    "    for i in range(len(filtered_corpus)):\n",
    "        score = 0.0\n",
    "        doc_length = doc_lengths[i]\n",
    "        doc_term_freq = doc_term_freqs[i]\n",
    "        for term in tokenized_query:\n",
    "            cf = corpus_term_freq[term]\n",
    "            p_corpus = cf / corpus_length if corpus_length > 0 else 0\n",
    "            tf = doc_term_freq[term]\n",
    "            # Dirichlet 平滑計算\n",
    "            p = (tf + mu * p_corpus) / (doc_length + mu)\n",
    "            if p > 0:\n",
    "                score += math.log(p)\n",
    "        scores.append(score)\n",
    "\n",
    "    # 取得得分最高的文件索引\n",
    "    most_similar_doc_index = scores.index(max(scores))\n",
    "    retrieved_doc_id = doc_ids[most_similar_doc_index]\n",
    "    return retrieved_doc_id # 傳回文檔名稱（整數）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVcOg8dsAaDB"
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1669413,
     "status": "ok",
     "timestamp": 1731130567633,
     "user": {
      "displayName": "Stan Wang (王家宏)",
      "userId": "17655850901040918693"
     },
     "user_tz": -480
    },
    "id": "bOi8yl0vq4ix",
    "outputId": "34aa04a6-0025-40aa-a54c-4e9f287f014d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 643/643 [03:49<00:00,  2.80it/s]\n",
      "100%|██████████| 1035/1035 [23:55<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "answer_dict = {\"answers\": []}  # 初始化字典\n",
    "\n",
    "source_path_insurance = os.path.join(source_path, 'insurance')  # 設定參考資料路徑\n",
    "corpus_dict_insurance = load_data(source_path_insurance)\n",
    "\n",
    "source_path_finance = os.path.join(source_path, 'finance')  # 設定參考資料路徑\n",
    "corpus_dict_finance = load_data(source_path_finance)\n",
    "\n",
    "with open(os.path.join(source_path, 'faq/pid_map_content.json'), 'rb') as f_s:\n",
    "    key_to_source_dict = json.load(f_s)  # 讀取參考資料文件\n",
    "    key_to_source_dict = {int(key): value for key, value in key_to_source_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-PHTADaAkcG"
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7672,
     "status": "ok",
     "timestamp": 1731140185907,
     "user": {
      "displayName": "Stan Wang (王家宏)",
      "userId": "17655850901040918693"
     },
     "user_tz": -480
    },
    "id": "Dm8--p75rwTN",
    "outputId": "ca8ac9e7-44c5-4f0e-eed8-7e9e77f6529e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing questions: 100%|██████████| 150/150 [00:07<00:00, 18.89it/s]\n"
     ]
    }
   ],
   "source": [
    "answer_dict = {\"answers\": []}  # 初始化字典\n",
    "\n",
    "with open(question_path, 'rb') as f:\n",
    "    qs_ref = json.load(f)  # 讀取問題檔案\n",
    "\n",
    "for q_dict in tqdm(qs_ref['questions'], desc=\"Processing questions\"):\n",
    "  if q_dict['category'] == 'finance':\n",
    "      # 進行檢索\n",
    "      retrieved = LMIR_retrieve(q_dict['query'], q_dict['source'], corpus_dict_finance)\n",
    "      # 將結果加入字典\n",
    "      answer_dict['answers'].append({\"qid\": q_dict['qid'], \"retrieve\": retrieved})\n",
    "\n",
    "  elif q_dict['category'] == 'insurance':\n",
    "      retrieved = LMIR_retrieve(q_dict['query'], q_dict['source'], corpus_dict_insurance)\n",
    "      answer_dict['answers'].append({\"qid\": q_dict['qid'], \"retrieve\": retrieved})\n",
    "\n",
    "  elif q_dict['category'] == 'faq':\n",
    "      corpus_dict_faq = {key: str(value) for key, value in key_to_source_dict.items() if key in q_dict['source']}\n",
    "      retrieved = LMIR_retrieve(q_dict['query'], q_dict['source'], corpus_dict_faq)\n",
    "      answer_dict['answers'].append({\"qid\": q_dict['qid'], \"retrieve\": retrieved})\n",
    "\n",
    "  else:\n",
    "      raise ValueError(\"Something went wrong\")  # 如果過程有問題，拋出錯誤\n",
    "\n",
    "# 將答案字典保存為json文件\n",
    "with open(output_path, 'w', encoding='utf8') as f:\n",
    "  json.dump(answer_dict, f, ensure_ascii=False, indent=4)  # 儲存檔案，確保格式和非ASCII字符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0miB8LhbAp6X"
   },
   "source": [
    "## Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1731140186402,
     "user": {
      "displayName": "Stan Wang (王家宏)",
      "userId": "17655850901040918693"
     },
     "user_tz": -480
    },
    "id": "h1vcpNMN1OZ4"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the ground truth JSON file\n",
    "with open(truth_sample_path, 'r', encoding='utf-8') as f:\n",
    "    ground_truth_data = json.load(f)\n",
    "\n",
    "# Load your result JSON file\n",
    "with open(pred_sample_path, 'r', encoding='utf-8') as f:\n",
    "    your_result_data = json.load(f)\n",
    "\n",
    "\n",
    "# Ground truth mapping\n",
    "ground_truths = {}\n",
    "for item in ground_truth_data['ground_truths']:\n",
    "    qid = item['qid']\n",
    "    retrieve = item['retrieve']\n",
    "    category = item.get('category', 'unknown')  # Get category if needed\n",
    "    ground_truths[qid] = {\n",
    "        'retrieve': retrieve,\n",
    "        'category': category\n",
    "    }\n",
    "\n",
    "# Your result mapping\n",
    "your_results = {}\n",
    "for item in your_result_data['answers']:\n",
    "    qid = item['qid']\n",
    "    retrieve = item['retrieve']\n",
    "    your_results[qid] = retrieve\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "category_correct = defaultdict(int)\n",
    "category_total = defaultdict(int)\n",
    "\n",
    "for qid, gt in ground_truths.items():\n",
    "    gt_retrieve = gt['retrieve']\n",
    "    category = gt['category']\n",
    "    your_retrieve = your_results.get(qid)\n",
    "\n",
    "    if your_retrieve is not None:\n",
    "        category_total[category] += 1\n",
    "        if your_retrieve == gt_retrieve:\n",
    "            category_correct[category] += 1\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "incorrect_qids = []\n",
    "\n",
    "for qid, gt in ground_truths.items():\n",
    "    gt_retrieve = gt['retrieve']\n",
    "    your_retrieve = your_results.get(qid)\n",
    "\n",
    "    if your_retrieve is not None:\n",
    "        total += 1\n",
    "        if your_retrieve == gt_retrieve:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect_qids.append({\n",
    "                'qid': qid,\n",
    "                'ground_truth': gt_retrieve,\n",
    "                'your_retrieve': your_retrieve,\n",
    "                'category': gt['category']\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Warning: QID {qid} not found in your results.\")\n",
    "\n",
    "# Handle any qids in your results that are not in ground truth\n",
    "extra_qids = set(your_results.keys()) - set(ground_truths.keys())\n",
    "if extra_qids:\n",
    "    print(f\"These QIDs are in your results but not in ground truth: {extra_qids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSXuSTRbGiGK"
   },
   "source": [
    "## Print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1731140186402,
     "user": {
      "displayName": "Stan Wang (王家宏)",
      "userId": "17655850901040918693"
     },
     "user_tz": -480
    },
    "id": "x3QeI0vJGlSk",
    "outputId": "9bda7755-c448-45fe-c03f-7a5a0c394dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category-wise Accuracy:\n",
      "- insurance: 90.00%\n",
      "- finance: 80.00%\n",
      "- faq: 94.00%\n",
      "Total Questions Evaluated: 150\n",
      "Correctly Retrieved: 132\n",
      "Accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Category-wise Accuracy:\")\n",
    "for category in category_total:\n",
    "    cat_accuracy = category_correct[category] / category_total[category]\n",
    "    print(f\"- {category}: {cat_accuracy * 100:.2f}%\")\n",
    "\n",
    "if total > 0:\n",
    "    accuracy = correct / total\n",
    "    print(f\"Total Questions Evaluated: {total}\")\n",
    "    print(f\"Correctly Retrieved: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"No matching QIDs found between your results and ground truth.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Te6A_fK0LuG"
   },
   "source": [
    "FT\n",
    "Category-wise Accuracy:\n",
    "- insurance: 82.00%\n",
    "- finance: 82.00%\n",
    "- faq: 94.00%\n",
    "Total Questions Evaluated: 150\n",
    "Correctly Retrieved: 129\n",
    "Accuracy: 86.00%"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "_qfSFD3B_nL1",
    "J27P6Jld_zH-",
    "DTSAbytJRAV2",
    "opqvwZ3TAKil",
    "gVcOg8dsAaDB",
    "hyYMjFRRAEvt",
    "mtkPE61tAUbr",
    "0miB8LhbAp6X"
   ],
   "provenance": [
    {
     "file_id": "1tthfIoP7MSbhFrh97glmgR1Uka72GsnP",
     "timestamp": 1731127866268
    },
    {
     "file_id": "1PHsCafLQhziIzXFG_gK0JAzdL99kXf0n",
     "timestamp": 1731077599921
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
